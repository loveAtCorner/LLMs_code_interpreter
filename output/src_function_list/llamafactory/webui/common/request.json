{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "返回下面这个脚本当中所有函数或者类的名称，及其对应的功能\n返回内容的格式需要遵循markdown表格的形式\n\n```python\nimport json\nimport os\nfrom collections import defaultdict\nfrom typing import Any, Dict, Optional, Tuple\n\nfrom yaml import safe_dump, safe_load\n\nfrom ..extras.constants import (\n    CHECKPOINT_NAMES,\n    DATA_CONFIG,\n    DEFAULT_TEMPLATE,\n    PEFT_METHODS,\n    STAGES_USE_PAIR_DATA,\n    SUPPORTED_MODELS,\n    TRAINING_STAGES,\n    VISION_MODELS,\n    DownloadSource,\n)\nfrom ..extras.logging import get_logger\nfrom ..extras.misc import use_modelscope\nfrom ..extras.packages import is_gradio_available\n\n\nif is_gradio_available():\n    import gradio as gr\n\n\nlogger = get_logger(__name__)\n\n\nDEFAULT_CACHE_DIR = \"cache\"\nDEFAULT_CONFIG_DIR = \"config\"\nDEFAULT_DATA_DIR = \"data\"\nDEFAULT_SAVE_DIR = \"saves\"\nUSER_CONFIG = \"user_config.yaml\"\nQUANTIZATION_BITS = [\"8\", \"6\", \"5\", \"4\", \"3\", \"2\", \"1\"]\nGPTQ_BITS = [\"8\", \"4\", \"3\", \"2\"]\n\n\ndef get_save_dir(*paths: str) -> os.PathLike:\n    r\n    if os.path.sep in paths[-1]:\n        logger.warning(\"Found complex path, some features may be not available.\")\n        return paths[-1]\n\n    paths = (path.replace(\" \", \"\").strip() for path in paths)\n    return os.path.join(DEFAULT_SAVE_DIR, *paths)\n\n\ndef get_config_path() -> os.PathLike:\n    r\n    return os.path.join(DEFAULT_CACHE_DIR, USER_CONFIG)\n\n\ndef load_config() -> Dict[str, Any]:\n    r\n    try:\n        with open(get_config_path(), \"r\", encoding=\"utf-8\") as f:\n            return safe_load(f)\n    except Exception:\n        return {\"lang\": None, \"last_model\": None, \"path_dict\": {}, \"cache_dir\": None}\n\n\ndef save_config(lang: str, model_name: Optional[str] = None, model_path: Optional[str] = None) -> None:\n    r\n    os.makedirs(DEFAULT_CACHE_DIR, exist_ok=True)\n    user_config = load_config()\n    user_config[\"lang\"] = lang or user_config[\"lang\"]\n    if model_name:\n        user_config[\"last_model\"] = model_name\n\n    if model_name and model_path:\n        user_config[\"path_dict\"][model_name] = model_path\n\n    with open(get_config_path(), \"w\", encoding=\"utf-8\") as f:\n        safe_dump(user_config, f)\n\n\ndef get_model_path(model_name: str) -> str:\n    r\n    user_config = load_config()\n    path_dict: Dict[\"DownloadSource\", str] = SUPPORTED_MODELS.get(model_name, defaultdict(str))\n    model_path = user_config[\"path_dict\"].get(model_name, \"\") or path_dict.get(DownloadSource.DEFAULT, \"\")\n    if (\n        use_modelscope()\n        and path_dict.get(DownloadSource.MODELSCOPE)\n        and model_path == path_dict.get(DownloadSource.DEFAULT)\n    ):  \n        model_path = path_dict.get(DownloadSource.MODELSCOPE)\n\n    return model_path\n\n\ndef get_prefix(model_name: str) -> str:\n    r\n    return model_name.split(\"-\")[0]\n\n\ndef get_model_info(model_name: str) -> Tuple[str, str, bool]:\n    r\n    return get_model_path(model_name), get_template(model_name), get_visual(model_name)\n\n\ndef get_template(model_name: str) -> str:\n    r\n    if model_name and model_name.endswith(\"Chat\") and get_prefix(model_name) in DEFAULT_TEMPLATE:\n        return DEFAULT_TEMPLATE[get_prefix(model_name)]\n    return \"default\"\n\n\ndef get_visual(model_name: str) -> bool:\n    r\n    return get_prefix(model_name) in VISION_MODELS\n\n\ndef list_checkpoints(model_name: str, finetuning_type: str) -> \"gr.Dropdown\":\n    r\n    checkpoints = []\n    if model_name:\n        save_dir = get_save_dir(model_name, finetuning_type)\n        if save_dir and os.path.isdir(save_dir):\n            for checkpoint in os.listdir(save_dir):\n                if os.path.isdir(os.path.join(save_dir, checkpoint)) and any(\n                    os.path.isfile(os.path.join(save_dir, checkpoint, name)) for name in CHECKPOINT_NAMES\n                ):\n                    checkpoints.append(checkpoint)\n\n    if finetuning_type in PEFT_METHODS:\n        return gr.Dropdown(value=[], choices=checkpoints, multiselect=True)\n    else:\n        return gr.Dropdown(value=None, choices=checkpoints, multiselect=False)\n\n\ndef load_dataset_info(dataset_dir: str) -> Dict[str, Dict[str, Any]]:\n    r\n    if dataset_dir == \"ONLINE\":\n        logger.info(\"dataset_dir is ONLINE, using online dataset.\")\n        return {}\n\n    try:\n        with open(os.path.join(dataset_dir, DATA_CONFIG), \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except Exception as err:\n        logger.warning(\"Cannot open {} due to {}.\".format(os.path.join(dataset_dir, DATA_CONFIG), str(err)))\n        return {}\n\n\ndef list_datasets(dataset_dir: str = None, training_stage: str = list(TRAINING_STAGES.keys())[0]) -> \"gr.Dropdown\":\n    r\n    dataset_info = load_dataset_info(dataset_dir if dataset_dir is not None else DEFAULT_DATA_DIR)\n    ranking = TRAINING_STAGES[training_stage] in STAGES_USE_PAIR_DATA\n    datasets = [k for k, v in dataset_info.items() if v.get(\"ranking\", False) == ranking]\n    return gr.Dropdown(choices=datasets)\n```"
        }
    ],
    "temperature": 0
}