{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "返回下面这个脚本当中所有函数或者类的名称，及其对应的功能\n返回内容的格式需要遵循markdown表格的形式\n\n```python\nfrom typing import TYPE_CHECKING, Tuple\n\nimport torch\nimport transformers.models\nfrom transformers.activations import ACT2FN\nfrom transformers.utils import logging\n\nfrom ...extras.logging import get_logger\n\n\nif TYPE_CHECKING:\n    from transformers import LlavaConfig, PretrainedConfig, PreTrainedModel\n\n    from ...hparams import ModelArguments\n\n\nlogger = get_logger(__name__)\ntransformers_logger = logging.get_logger(__name__)\n\n\nclass LlavaMultiModalProjectorForYiVL(torch.nn.Module):\n    def __init__(self, config: \"LlavaConfig\") -> None:\n        super().__init__()\n\n        self.config = config\n        if config is None:\n            return\n\n        self.linear_1 = torch.nn.Linear(config.vision_config.hidden_size, config.text_config.hidden_size, bias=True)\n        self.linear_2 = torch.nn.LayerNorm(config.text_config.hidden_size, bias=True)\n        self.linear_3 = torch.nn.Linear(config.text_config.hidden_size, config.text_config.hidden_size, bias=True)\n        self.linear_4 = torch.nn.LayerNorm(config.text_config.hidden_size, bias=True)\n        self.act = ACT2FN[config.projector_hidden_act]\n\n    def forward(self, image_features: \"torch.Tensor\") -> \"torch.Tensor\":\n        hidden_states = self.linear_1(image_features)\n        hidden_states = self.linear_2(hidden_states)\n        hidden_states = self.act(hidden_states)\n        hidden_states = self.linear_3(hidden_states)\n        hidden_states = self.linear_4(hidden_states)\n        if hidden_states.dtype == torch.float32:\n            if torch.is_autocast_enabled():\n                target_dtype = torch.get_autocast_gpu_dtype()\n            elif hasattr(self.config, \"_pre_quantization_dtype\"):\n                target_dtype = self.config._pre_quantization_dtype\n            else:\n                target_dtype = self.linear_1.weight.dtype\n\n            transformers_logger.warning_once(\"The hidden states seems to be silently casted in float32.\")\n            hidden_states = hidden_states.to(target_dtype)\n\n        return hidden_states\n\n\nclass LlavaMultiModalProjectorForYiVLForVLLM(LlavaMultiModalProjectorForYiVL):\n    def __init__(self, vision_hidden_size: int, text_hidden_size: int, projector_hidden_act: str) -> None:\n        super().__init__(config=None)\n\n        self.linear_1 = torch.nn.Linear(vision_hidden_size, text_hidden_size, bias=True)\n        self.linear_2 = torch.nn.LayerNorm(text_hidden_size, bias=True)\n        self.linear_3 = torch.nn.Linear(text_hidden_size, text_hidden_size, bias=True)\n        self.linear_4 = torch.nn.LayerNorm(text_hidden_size, bias=True)\n        self.act = ACT2FN[projector_hidden_act]\n\n\ndef autocast_projector_dtype(\n    model: \"PreTrainedModel\", model_args: \"ModelArguments\", mm_projector_name: str = \"multi_modal_projector\"\n) -> None:\n    def _mm_projector_forward_post_hook(\n        module: \"torch.nn.Module\", args: Tuple[\"torch.Tensor\"], output: \"torch.Tensor\"\n    ) -> \"torch.Tensor\":\n        return output.to(model_args.compute_dtype)\n\n    if hasattr(model, mm_projector_name) and getattr(model, \"quantization_method\", None):\n        logger.info(\"Casting multimodal projector outputs in {}.\".format(model_args.compute_dtype))\n        mm_projector: \"torch.nn.Module\" = getattr(model, mm_projector_name)\n        mm_projector.register_forward_hook(_mm_projector_forward_post_hook)\n\n\ndef configure_visual_model(config: \"PretrainedConfig\") -> None:\n    if getattr(config, \"model_type\", None) == \"llava\":  \n        setattr(config, \"hidden_size\", getattr(config.text_config, \"hidden_size\", None))\n\n    if getattr(config, \"is_yi_vl_derived_model\", None):\n        logger.info(\"Detected Yi-VL model, applying projector patch.\")\n        transformers.models.llava.modeling_llava.LlavaMultiModalProjector = LlavaMultiModalProjectorForYiVL\n```"
        }
    ],
    "temperature": 0
}