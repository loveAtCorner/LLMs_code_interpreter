{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "返回下面这个脚本当中所有函数或者类的名称，及其对应的功能\n返回内容的格式需要遵循markdown表格的形式\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, Literal, Sequence\n\nimport torch\nfrom transformers import DataCollatorForSeq2Seq\n\n\ndef prepare_4d_attention_mask(attention_mask_with_indices: \"torch.Tensor\", dtype: \"torch.dtype\") -> \"torch.Tensor\":\n    r\n    bsz, seq_len = attention_mask_with_indices.size()\n    min_dtype = torch.finfo(dtype).min\n    expanded_mask = attention_mask_with_indices[:, None, None, :].expand(bsz, 1, seq_len, seq_len)\n    \n    padding_mask = torch.where(expanded_mask != 0, 1, 0)\n    \n    attention_mask_4d = torch.eq(expanded_mask, expanded_mask.transpose(-1, -2)).int() * padding_mask\n    \n    attention_mask_4d *= torch.tril(torch.ones((seq_len, seq_len), dtype=torch.long))\n    \n    attention_mask_4d = torch.where(attention_mask_4d != 0, torch.tensor(0, dtype=dtype), min_dtype)\n    return attention_mask_4d\n\n\n@dataclass\nclass SFTDataCollatorWith4DAttentionMask(DataCollatorForSeq2Seq):\n    r\n\n    block_diag_attn: bool = False\n    attn_implementation: Literal[\"eager\", \"sdpa\", \"flash_attention_2\"] = \"eager\"\n    compute_dtype: \"torch.dtype\" = torch.float32\n\n    def __call__(self, features: Sequence[Dict[str, Any]]) -> Dict[str, \"torch.Tensor\"]:\n        features = super().__call__(features)\n        if self.block_diag_attn and self.attn_implementation != \"flash_attention_2\":\n            features[\"attention_mask\"] = prepare_4d_attention_mask(features[\"attention_mask\"], self.compute_dtype)\n\n        return features\n\n\n@dataclass\nclass PairwiseDataCollatorWithPadding(DataCollatorForSeq2Seq):\n    r\n\n    def __call__(self, features: Sequence[Dict[str, Any]]) -> Dict[str, \"torch.Tensor\"]:\n        r\n        concatenated_features = []\n        for key in (\"chosen\", \"rejected\"):\n            for feature in features:\n                target_feature = {\n                    \"input_ids\": feature[\"{}_input_ids\".format(key)],\n                    \"attention_mask\": feature[\"{}_attention_mask\".format(key)],\n                    \"labels\": feature[\"{}_labels\".format(key)],\n                }\n                if \"pixel_values\" in feature:\n                    target_feature[\"pixel_values\"] = feature[\"pixel_values\"]\n\n                if \"{}_token_type_ids\".format(key) in feature:\n                    target_feature[\"token_type_ids\"] = feature[\"{}_token_type_ids\".format(key)]\n\n                concatenated_features.append(target_feature)\n\n        return super().__call__(concatenated_features)\n\n\n@dataclass\nclass KTODataCollatorWithPadding(DataCollatorForSeq2Seq):\n    r\n\n    def __call__(self, features: Sequence[Dict[str, Any]]) -> Dict[str, \"torch.Tensor\"]:\n        target_features = []\n        kl_features = []\n        kto_tags = []\n        for feature in features:\n            target_feature = {\n                \"input_ids\": feature[\"input_ids\"],\n                \"attention_mask\": feature[\"attention_mask\"],\n                \"labels\": feature[\"labels\"],\n            }\n            kl_feature = {\n                \"input_ids\": feature[\"kl_input_ids\"],\n                \"attention_mask\": feature[\"kl_attention_mask\"],\n                \"labels\": feature[\"kl_labels\"],\n            }\n            if \"pixel_values\" in feature:\n                target_feature[\"pixel_values\"] = feature[\"pixel_values\"]\n\n            if \"token_type_ids\" in feature:\n                target_feature[\"token_type_ids\"] = feature[\"token_type_ids\"]\n                kl_feature[\"token_type_ids\"] = feature[\"kl_token_type_ids\"]\n\n            target_features.append(target_feature)\n            kl_features.append(kl_feature)\n            kto_tags.append(feature[\"kto_tags\"])\n\n        batch = super().__call__(target_features)\n        kl_batch = super().__call__(kl_features)\n        batch[\"kl_input_ids\"] = kl_batch[\"input_ids\"]\n        batch[\"kl_attention_mask\"] = kl_batch[\"attention_mask\"]\n        batch[\"kl_labels\"] = kl_batch[\"labels\"]\n        if \"token_type_ids\" in batch:\n            batch[\"kl_token_type_ids\"] = kl_batch[\"token_type_ids\"]\n\n        batch[\"kto_tags\"] = torch.tensor(kto_tags)\n        return batch\n```"
        }
    ],
    "temperature": 0
}