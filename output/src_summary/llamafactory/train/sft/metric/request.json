{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Dict\n\nimport numpy as np\nimport torch\nfrom transformers.utils import is_jieba_available, is_nltk_available\n\nfrom ...extras.constants import IGNORE_INDEX\nfrom ...extras.packages import is_rouge_available\n\n\nif TYPE_CHECKING:\n    from transformers import EvalPrediction, PreTrainedTokenizer\n\n\nif is_jieba_available():\n    import jieba  \n\n\nif is_nltk_available():\n    from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n\n\nif is_rouge_available():\n    from rouge_chinese import Rouge\n\n\ndef compute_accuracy(eval_preds: \"EvalPrediction\") -> Dict[str, float]:\n    preds, labels = eval_preds.predictions, eval_preds.label_ids\n    accuracies = []\n    for i in range(len(preds)):\n        pred, label = preds[i, :-1], labels[i, 1:]\n        label_mask = label != IGNORE_INDEX\n        accuracies.append(np.mean(pred[label_mask] == label[label_mask]))\n\n    return {\"accuracy\": float(np.mean(accuracies))}\n\n\ndef eval_logit_processor(logits: \"torch.Tensor\", labels: \"torch.Tensor\") -> \"torch.Tensor\":\n    logits = logits[0] if isinstance(logits, (list, tuple)) else logits\n    return torch.argmax(logits, dim=-1)\n\n\n@dataclass\nclass ComputeMetrics:\n    r\n\n    tokenizer: \"PreTrainedTokenizer\"\n\n    def __call__(self, eval_preds: \"EvalPrediction\") -> Dict[str, float]:\n        r\n        preds, labels = eval_preds.predictions, eval_preds.label_ids\n        score_dict = {\"rouge-1\": [], \"rouge-2\": [], \"rouge-l\": [], \"bleu-4\": []}\n\n        preds = np.where(preds != IGNORE_INDEX, preds, self.tokenizer.pad_token_id)\n        labels = np.where(labels != IGNORE_INDEX, labels, self.tokenizer.pad_token_id)\n\n        decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n        for pred, label in zip(decoded_preds, decoded_labels):\n            hypothesis = list(jieba.cut(pred))\n            reference = list(jieba.cut(label))\n\n            if len(\" \".join(hypothesis).split()) == 0 or len(\" \".join(reference).split()) == 0:\n                result = {\"rouge-1\": {\"f\": 0.0}, \"rouge-2\": {\"f\": 0.0}, \"rouge-l\": {\"f\": 0.0}}\n            else:\n                rouge = Rouge()\n                scores = rouge.get_scores(\" \".join(hypothesis), \" \".join(reference))\n                result = scores[0]\n\n            for k, v in result.items():\n                score_dict[k].append(round(v[\"f\"] * 100, 4))\n\n            bleu_score = sentence_bleu([list(label)], list(pred), smoothing_function=SmoothingFunction().method3)\n            score_dict[\"bleu-4\"].append(round(bleu_score * 100, 4))\n\n        return {k: float(np.mean(v)) for k, v in score_dict.items()}\n```"
        }
    ],
    "temperature": 0
}