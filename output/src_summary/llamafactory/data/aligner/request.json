{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nimport os\nfrom functools import partial\nfrom typing import TYPE_CHECKING, Any, Dict, List, Union\n\nfrom datasets import Features\n\nfrom ..extras.logging import get_logger\nfrom .data_utils import Role\n\n\nif TYPE_CHECKING:\n    from datasets import Dataset, IterableDataset\n    from transformers import Seq2SeqTrainingArguments\n\n    from ..hparams import DataArguments\n    from .parser import DatasetAttr\n\n\nlogger = get_logger(__name__)\n\n\ndef _convert_images(images: List[Any], dataset_attr: \"DatasetAttr\", data_args: \"DataArguments\") -> List[Any]:\n    r\n    outputs = []\n    if dataset_attr.load_from in [\"script\", \"file\"]:\n        for image in images:\n            if isinstance(image, str) and os.path.isfile(os.path.join(data_args.dataset_dir, image)):\n                outputs.append(os.path.join(data_args.dataset_dir, image))\n            else:\n                outputs.append(image)\n\n    return outputs\n\n\ndef convert_alpaca(\n    examples: Dict[str, List[Any]], dataset_attr: \"DatasetAttr\", data_args: \"DataArguments\"\n) -> Dict[str, List[Any]]:\n    r\n    outputs = {\"prompt\": [], \"response\": [], \"system\": [], \"tools\": [], \"images\": []}\n    convert_images = partial(_convert_images, dataset_attr=dataset_attr, data_args=data_args)\n    for i in range(len(examples[dataset_attr.prompt])):\n        prompt = []\n        if dataset_attr.history and isinstance(examples[dataset_attr.history][i], list):\n            for old_prompt, old_response in examples[dataset_attr.history][i]:\n                prompt.append({\"role\": Role.USER.value, \"content\": old_prompt})\n                prompt.append({\"role\": Role.ASSISTANT.value, \"content\": old_response})\n\n        content = []\n        if dataset_attr.prompt and examples[dataset_attr.prompt][i]:\n            content.append(examples[dataset_attr.prompt][i])\n\n        if dataset_attr.query and examples[dataset_attr.query][i]:\n            content.append(examples[dataset_attr.query][i])\n\n        prompt.append({\"role\": Role.USER.value, \"content\": \"\\n\".join(content)})  \n\n        if dataset_attr.kto_tag and isinstance(examples[dataset_attr.kto_tag][i], bool):  \n            response = [{\"role\": Role.ASSISTANT.value, \"content\": examples[dataset_attr.response][i]}]\n            if examples[dataset_attr.kto_tag][i]:\n                response = response + [{\"role\": Role.ASSISTANT.value, \"content\": \"\"}]\n            else:\n                response = [{\"role\": Role.ASSISTANT.value, \"content\": \"\"}] + response\n        elif (\n            dataset_attr.ranking\n            and isinstance(examples[dataset_attr.chosen][i], str)\n            and isinstance(examples[dataset_attr.rejected][i], str)\n        ):  \n            response = [\n                {\"role\": Role.ASSISTANT.value, \"content\": examples[dataset_attr.chosen][i]},\n                {\"role\": Role.ASSISTANT.value, \"content\": examples[dataset_attr.rejected][i]},\n            ]\n        elif dataset_attr.response and isinstance(examples[dataset_attr.response][i], str):  \n            response = [{\"role\": Role.ASSISTANT.value, \"content\": examples[dataset_attr.response][i]}]\n        else:  \n            response = []\n\n        outputs[\"prompt\"].append(prompt)\n        outputs[\"response\"].append(response)\n        outputs[\"system\"].append(examples[dataset_attr.system][i] if dataset_attr.system else \"\")\n        outputs[\"tools\"].append(examples[dataset_attr.tools][i] if dataset_attr.tools else \"\")\n        outputs[\"images\"].append(convert_images(examples[dataset_attr.images][i]) if dataset_attr.images else [])\n\n    return outputs\n\n\ndef convert_sharegpt(\n    examples: Dict[str, List[Any]], dataset_attr: \"DatasetAttr\", data_args: \"DataArguments\"\n) -> Dict[str, List[Any]]:\n    r\n    outputs = {\"prompt\": [], \"response\": [], \"system\": [], \"tools\": [], \"images\": []}\n    convert_images = partial(_convert_images, dataset_attr=dataset_attr, data_args=data_args)\n    tag_mapping = {\n        dataset_attr.user_tag: Role.USER.value,\n        dataset_attr.assistant_tag: Role.ASSISTANT.value,\n        dataset_attr.observation_tag: Role.OBSERVATION.value,\n        dataset_attr.function_tag: Role.FUNCTION.value,\n        dataset_attr.system_tag: Role.SYSTEM.value,\n    }\n    odd_tags = (dataset_attr.user_tag, dataset_attr.observation_tag)\n    even_tags = (dataset_attr.assistant_tag, dataset_attr.function_tag)\n    accept_tags = (odd_tags, even_tags)\n    for i, messages in enumerate(examples[dataset_attr.messages]):\n        if dataset_attr.system_tag and messages[0][dataset_attr.role_tag] == dataset_attr.system_tag:\n            system = messages[0][dataset_attr.content_tag]\n            messages = messages[1:]\n        else:\n            system = examples[dataset_attr.system][i] if dataset_attr.system else \"\"\n\n        if len(messages) == 0:\n            continue\n\n        aligned_messages = []\n        broken_data = False\n        for turn_idx, message in enumerate(messages):\n            if message[dataset_attr.role_tag] not in accept_tags[turn_idx % 2]:\n                logger.warning(\"Invalid role tag in {}.\".format(messages))\n                broken_data = True\n\n            aligned_messages.append(\n                {\"role\": tag_mapping[message[dataset_attr.role_tag]], \"content\": message[dataset_attr.content_tag]}\n            )\n\n        if (not dataset_attr.ranking and len(aligned_messages) % 2 != 0) or (\n            dataset_attr.ranking and len(aligned_messages) % 2 == 0\n        ):\n            logger.warning(\"Invalid message count in {}.\".format(messages))\n            broken_data = True\n\n        if dataset_attr.kto_tag and isinstance(examples[dataset_attr.kto_tag][i], bool):  \n            prompt = aligned_messages[:-1]\n            response = aligned_messages[-1:]\n            if examples[dataset_attr.kto_tag][i]:\n                response = response + [{\"role\": Role.ASSISTANT.value, \"content\": \"\"}]\n            else:\n                response = [{\"role\": Role.ASSISTANT.value, \"content\": \"\"}] + response\n        elif (\n            dataset_attr.ranking\n            and isinstance(examples[dataset_attr.chosen][i], dict)\n            and isinstance(examples[dataset_attr.rejected][i], dict)\n        ):  \n            chosen = examples[dataset_attr.chosen][i]\n            rejected = examples[dataset_attr.rejected][i]\n            if (\n                chosen[dataset_attr.role_tag] not in accept_tags[-1]\n                or rejected[dataset_attr.role_tag] not in accept_tags[-1]\n            ):\n                logger.warning(\"Invalid role tag in {}.\".format([chosen, rejected]))\n                broken_data = True\n\n            prompt = aligned_messages\n            response = [\n                {\"role\": tag_mapping[chosen[dataset_attr.role_tag]], \"content\": chosen[dataset_attr.content_tag]},\n                {\"role\": tag_mapping[rejected[dataset_attr.role_tag]], \"content\": rejected[dataset_attr.content_tag]},\n            ]\n        else:  \n            prompt = aligned_messages[:-1]\n            response = aligned_messages[-1:]\n\n        if broken_data:\n            logger.warning(\"Skipping this abnormal example.\")\n            continue\n\n        outputs[\"prompt\"].append(prompt)\n        outputs[\"response\"].append(response)\n        outputs[\"system\"].append(system)\n        outputs[\"tools\"].append(examples[dataset_attr.tools][i] if dataset_attr.tools else \"\")\n        outputs[\"images\"].append(convert_images(examples[dataset_attr.images][i]) if dataset_attr.images else [])\n\n    return outputs\n\n\ndef align_dataset(\n    dataset: Union[\"Dataset\", \"IterableDataset\"],\n    dataset_attr: \"DatasetAttr\",\n    data_args: \"DataArguments\",\n    training_args: \"Seq2SeqTrainingArguments\",\n) -> Union[\"Dataset\", \"IterableDataset\"]:\n    r\n    if dataset_attr.formatting == \"alpaca\":\n        convert_func = partial(convert_alpaca, dataset_attr=dataset_attr, data_args=data_args)\n    else:\n        convert_func = partial(convert_sharegpt, dataset_attr=dataset_attr, data_args=data_args)\n\n    column_names = list(next(iter(dataset)).keys())\n    features = Features.from_dict(\n        {\n            \"prompt\": [\n                {\"role\": {\"dtype\": \"string\", \"_type\": \"Value\"}, \"content\": {\"dtype\": \"string\", \"_type\": \"Value\"}}\n            ],\n            \"response\": [\n                {\"role\": {\"dtype\": \"string\", \"_type\": \"Value\"}, \"content\": {\"dtype\": \"string\", \"_type\": \"Value\"}}\n            ],\n            \"system\": {\"dtype\": \"string\", \"_type\": \"Value\"},\n            \"tools\": {\"dtype\": \"string\", \"_type\": \"Value\"},\n            \"images\": [{\"_type\": \"Image\"}],\n        }\n    )\n    kwargs = {}\n    if not data_args.streaming:\n        kwargs = dict(\n            num_proc=data_args.preprocessing_num_workers,\n            load_from_cache_file=(not data_args.overwrite_cache) or (training_args.local_process_index != 0),\n            desc=\"Converting format of dataset\",\n        )\n\n    return dataset.map(\n        convert_func,\n        batched=True,\n        remove_columns=column_names,\n        features=features,\n        **kwargs,\n    )\n```"
        }
    ],
    "temperature": 0
}