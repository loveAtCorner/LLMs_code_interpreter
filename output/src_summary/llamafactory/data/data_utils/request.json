{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nfrom enum import Enum, unique\nfrom typing import TYPE_CHECKING, Dict, List, Sequence, Set, Union\n\nfrom datasets import concatenate_datasets, interleave_datasets\n\nfrom ..extras.logging import get_logger\n\n\nif TYPE_CHECKING:\n    from datasets import Dataset, IterableDataset\n    from transformers import Seq2SeqTrainingArguments\n\n    from ..hparams import DataArguments\n\n\nlogger = get_logger(__name__)\n\n\nSLOTS = Sequence[Union[str, Set[str], Dict[str, str]]]\n\n\n@unique\nclass Role(str, Enum):\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    SYSTEM = \"system\"\n    FUNCTION = \"function\"\n    OBSERVATION = \"observation\"\n\n\ndef merge_dataset(\n    all_datasets: List[Union[\"Dataset\", \"IterableDataset\"]],\n    data_args: \"DataArguments\",\n    training_args: \"Seq2SeqTrainingArguments\",\n) -> Union[\"Dataset\", \"IterableDataset\"]:\n    if len(all_datasets) == 1:\n        return all_datasets[0]\n    elif data_args.mix_strategy == \"concat\":\n        if data_args.streaming:\n            logger.warning(\"The samples between different datasets will not be mixed in streaming mode.\")\n        return concatenate_datasets(all_datasets)\n    elif data_args.mix_strategy.startswith(\"interleave\"):\n        if not data_args.streaming:\n            logger.warning(\"We recommend using `mix_strategy=concat` in non-streaming mode.\")\n        return interleave_datasets(\n            datasets=all_datasets,\n            probabilities=data_args.interleave_probs,\n            seed=training_args.seed,\n            stopping_strategy=\"first_exhausted\" if data_args.mix_strategy.endswith(\"under\") else \"all_exhausted\",\n        )\n    else:\n        raise ValueError(\"Unknown mixing strategy.\")\n\n\ndef split_dataset(\n    dataset: Union[\"Dataset\", \"IterableDataset\"], data_args: \"DataArguments\", training_args: \"Seq2SeqTrainingArguments\"\n) -> Dict[str, \"Dataset\"]:\n    if training_args.do_train:\n        if data_args.val_size > 1e-6:  \n            if data_args.streaming:\n                dataset = dataset.shuffle(buffer_size=data_args.buffer_size, seed=training_args.seed)\n                val_set = dataset.take(int(data_args.val_size))\n                train_set = dataset.skip(int(data_args.val_size))\n                return {\"train_dataset\": train_set, \"eval_dataset\": val_set}\n            else:\n                val_size = int(data_args.val_size) if data_args.val_size > 1 else data_args.val_size\n                dataset = dataset.train_test_split(test_size=val_size, seed=training_args.seed)\n                return {\"train_dataset\": dataset[\"train\"], \"eval_dataset\": dataset[\"test\"]}\n        else:\n            if data_args.streaming:\n                dataset = dataset.shuffle(buffer_size=data_args.buffer_size, seed=training_args.seed)\n            return {\"train_dataset\": dataset}\n    else:  \n        return {\"eval_dataset\": dataset}\n```"
        }
    ],
    "temperature": 0
}