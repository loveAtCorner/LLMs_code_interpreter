{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nfrom typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple\n\nfrom ...extras.constants import IGNORE_INDEX\nfrom ...extras.logging import get_logger\nfrom .processor_utils import get_paligemma_token_type_ids, get_pixel_values, infer_seqlen\n\n\nif TYPE_CHECKING:\n    from transformers import PreTrainedTokenizer, ProcessorMixin\n\n    from ...hparams import DataArguments\n    from ..template import Template\n\n\nlogger = get_logger(__name__)\n\n\ndef _encode_feedback_example(\n    prompt: Sequence[Dict[str, str]],\n    response: Sequence[Dict[str, str]],\n    kl_response: Sequence[Dict[str, str]],\n    system: Optional[str],\n    tools: Optional[str],\n    template: \"Template\",\n    tokenizer: \"PreTrainedTokenizer\",\n    processor: Optional[\"ProcessorMixin\"],\n    data_args: \"DataArguments\",\n) -> Tuple[List[int], List[int], List[int], List[int], bool]:\n    if processor is not None and not hasattr(processor, \"image_seq_length\"):  \n        prompt[0][\"content\"] = template.image_token + prompt[0][\"content\"]\n\n    if response[0][\"content\"]:  \n        kto_tag = True\n        messages = prompt + [response[0]]\n    else:  \n        kto_tag = False\n        messages = prompt + [response[1]]\n\n    if kl_response[0][\"content\"]:\n        kl_messages = prompt + [kl_response[0]]\n    else:\n        kl_messages = prompt + [kl_response[1]]\n\n    prompt_ids, response_ids = template.encode_oneturn(tokenizer, messages, system, tools)\n    kl_prompt_ids, kl_response_ids = template.encode_oneturn(tokenizer, kl_messages, system, tools)\n\n    if template.efficient_eos:\n        response_ids += [tokenizer.eos_token_id]\n        kl_response_ids += [tokenizer.eos_token_id]\n\n    if processor is not None and hasattr(processor, \"image_seq_length\"):  \n        image_token_id = tokenizer.convert_tokens_to_ids(template.image_token)\n        prompt_ids = [image_token_id] * getattr(processor, \"image_seq_length\") + prompt_ids\n        kl_prompt_ids = [image_token_id] * getattr(processor, \"image_seq_length\") + kl_prompt_ids\n\n    source_len, target_len = infer_seqlen(len(prompt_ids), len(response_ids), data_args.cutoff_len)\n    prompt_ids = prompt_ids[:source_len]\n    response_ids = response_ids[:target_len]\n    kl_source_len, kl_target_len = infer_seqlen(len(kl_prompt_ids), len(kl_response_ids), data_args.cutoff_len)\n    kl_prompt_ids = kl_prompt_ids[:kl_source_len]\n    kl_response_ids = kl_response_ids[:kl_target_len]\n\n    input_ids = prompt_ids + response_ids\n    labels = [IGNORE_INDEX] * source_len + response_ids\n    kl_input_ids = kl_prompt_ids + kl_response_ids\n    kl_labels = [IGNORE_INDEX] * kl_source_len + kl_response_ids\n\n    return input_ids, labels, kl_input_ids, kl_labels, kto_tag\n\n\ndef preprocess_feedback_dataset(\n    examples: Dict[str, List[Any]],\n    template: \"Template\",\n    tokenizer: \"PreTrainedTokenizer\",\n    processor: Optional[\"ProcessorMixin\"],\n    data_args: \"DataArguments\",\n) -> Dict[str, List[List[int]]]:\n    \n    kl_response = examples[\"response\"][::-1]\n    model_inputs = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        \"labels\": [],\n        \"kl_input_ids\": [],\n        \"kl_attention_mask\": [],\n        \"kl_labels\": [],\n        \"kto_tags\": [],\n    }\n    if processor is not None:\n        model_inputs[\"pixel_values\"] = []\n        if hasattr(processor, \"image_seq_length\"):  \n            model_inputs[\"token_type_ids\"] = []\n            model_inputs[\"kl_token_type_ids\"] = []\n\n    for i in range(len(examples[\"prompt\"])):\n        if len(examples[\"prompt\"][i]) % 2 != 1 or len(examples[\"response\"][i]) < 2:\n            logger.warning(\"Dropped invalid example: {}\".format(examples[\"prompt\"][i] + examples[\"response\"][i]))\n            continue\n\n        input_ids, labels, kl_input_ids, kl_labels, kto_tag = _encode_feedback_example(\n            prompt=examples[\"prompt\"][i],\n            response=examples[\"response\"][i],\n            kl_response=kl_response[i],\n            system=examples[\"system\"][i],\n            tools=examples[\"tools\"][i],\n            template=template,\n            tokenizer=tokenizer,\n            processor=processor,\n            data_args=data_args,\n        )\n        model_inputs[\"input_ids\"].append(input_ids)\n        model_inputs[\"attention_mask\"].append([1] * len(input_ids))\n        model_inputs[\"labels\"].append(labels)\n        model_inputs[\"kl_input_ids\"].append(kl_input_ids)\n        model_inputs[\"kl_attention_mask\"].append([1] * len(kl_input_ids))\n        model_inputs[\"kl_labels\"].append(kl_labels)\n        model_inputs[\"kto_tags\"].append(kto_tag)\n        if processor is not None:\n            model_inputs[\"pixel_values\"].append(get_pixel_values(examples[\"images\"][i], processor))\n            if hasattr(processor, \"image_seq_length\"):  \n                model_inputs[\"token_type_ids\"].append(get_paligemma_token_type_ids(len(input_ids), processor))\n                model_inputs[\"kl_token_type_ids\"].append(get_paligemma_token_type_ids(len(kl_input_ids), processor))\n\n    desirable_num = sum([1 for tag in model_inputs[\"kto_tags\"] if tag])\n    undesirable_num = len(model_inputs[\"kto_tags\"]) - desirable_num\n    if desirable_num == 0 or undesirable_num == 0:\n        logger.warning(\"Your dataset only has one preference type.\")\n\n    return model_inputs\n```"
        }
    ],
    "temperature": 0
}