{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nimport os\nimport random\nimport subprocess\nimport sys\nfrom enum import Enum, unique\n\nfrom . import launcher\nfrom .api.app import run_api\nfrom .chat.chat_model import run_chat\nfrom .eval.evaluator import run_eval\nfrom .extras.env import VERSION, print_env\nfrom .extras.logging import get_logger\nfrom .extras.misc import get_device_count\nfrom .train.tuner import export_model, run_exp\nfrom .webui.interface import run_web_demo, run_web_ui\n\n\nUSAGE = (\n    \"-\" * 70\n    + \"\\n\"\n    + \"| Usage:                                                             |\\n\"\n    + \"|   llamafactory-cli api -h: launch an OpenAI-style API server       |\\n\"\n    + \"|   llamafactory-cli chat -h: launch a chat interface in CLI         |\\n\"\n    + \"|   llamafactory-cli eval -h: evaluate models                        |\\n\"\n    + \"|   llamafactory-cli export -h: merge LoRA adapters and export model |\\n\"\n    + \"|   llamafactory-cli train -h: train models                          |\\n\"\n    + \"|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |\\n\"\n    + \"|   llamafactory-cli webui: launch LlamaBoard                        |\\n\"\n    + \"|   llamafactory-cli version: show version info                      |\\n\"\n    + \"-\" * 70\n)\n\nWELCOME = (\n    \"-\" * 58\n    + \"\\n\"\n    + \"| Welcome to LLaMA Factory, version {}\".format(VERSION)\n    + \" \" * (21 - len(VERSION))\n    + \"|\\n|\"\n    + \" \" * 56\n    + \"|\\n\"\n    + \"| Project page: https://github.com/hiyouga/LLaMA-Factory |\\n\"\n    + \"-\" * 58\n)\n\nlogger = get_logger(__name__)\n\n\n@unique\nclass Command(str, Enum):\n    API = \"api\"\n    CHAT = \"chat\"\n    ENV = \"env\"\n    EVAL = \"eval\"\n    EXPORT = \"export\"\n    TRAIN = \"train\"\n    WEBDEMO = \"webchat\"\n    WEBUI = \"webui\"\n    VER = \"version\"\n    HELP = \"help\"\n\n\ndef main():\n    command = sys.argv.pop(1) if len(sys.argv) != 1 else Command.HELP\n    if command == Command.API:\n        run_api()\n    elif command == Command.CHAT:\n        run_chat()\n    elif command == Command.ENV:\n        print_env()\n    elif command == Command.EVAL:\n        run_eval()\n    elif command == Command.EXPORT:\n        export_model()\n    elif command == Command.TRAIN:\n        force_torchrun = os.environ.get(\"FORCE_TORCHRUN\", \"0\").lower() in [\"true\", \"1\"]\n        if force_torchrun or get_device_count() > 1:\n            master_addr = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n            master_port = os.environ.get(\"MASTER_PORT\", str(random.randint(20001, 29999)))\n            logger.info(\"Initializing distributed tasks at: {}:{}\".format(master_addr, master_port))\n            process = subprocess.run(\n                (\n                    \"torchrun --nnodes {nnodes} --node_rank {node_rank} --nproc_per_node {nproc_per_node} \"\n                    \"--master_addr {master_addr} --master_port {master_port} {file_name} {args}\"\n                ).format(\n                    nnodes=os.environ.get(\"NNODES\", \"1\"),\n                    node_rank=os.environ.get(\"RANK\", \"0\"),\n                    nproc_per_node=os.environ.get(\"NPROC_PER_NODE\", str(get_device_count())),\n                    master_addr=master_addr,\n                    master_port=master_port,\n                    file_name=launcher.__file__,\n                    args=\" \".join(sys.argv[1:]),\n                ),\n                shell=True,\n            )\n            sys.exit(process.returncode)\n        else:\n            run_exp()\n    elif command == Command.WEBDEMO:\n        run_web_demo()\n    elif command == Command.WEBUI:\n        run_web_ui()\n    elif command == Command.VER:\n        print(WELCOME)\n    elif command == Command.HELP:\n        print(USAGE)\n    else:\n        raise NotImplementedError(\"Unknown command: {}\".format(command))\n```"
        }
    ],
    "temperature": 0
}