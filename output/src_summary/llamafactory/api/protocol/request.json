{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nimport time\nfrom enum import Enum, unique\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import Literal\n\n\n@unique\nclass Role(str, Enum):\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    SYSTEM = \"system\"\n    FUNCTION = \"function\"\n    TOOL = \"tool\"\n\n\n@unique\nclass Finish(str, Enum):\n    STOP = \"stop\"\n    LENGTH = \"length\"\n    TOOL = \"tool_calls\"\n\n\nclass ModelCard(BaseModel):\n    id: str\n    object: Literal[\"model\"] = \"model\"\n    created: int = Field(default_factory=lambda: int(time.time()))\n    owned_by: Literal[\"owner\"] = \"owner\"\n\n\nclass ModelList(BaseModel):\n    object: Literal[\"list\"] = \"list\"\n    data: List[ModelCard] = []\n\n\nclass Function(BaseModel):\n    name: str\n    arguments: str\n\n\nclass FunctionDefinition(BaseModel):\n    name: str\n    description: str\n    parameters: Dict[str, Any]\n\n\nclass FunctionAvailable(BaseModel):\n    type: Literal[\"function\", \"code_interpreter\"] = \"function\"\n    function: Optional[FunctionDefinition] = None\n\n\nclass FunctionCall(BaseModel):\n    id: str\n    type: Literal[\"function\"] = \"function\"\n    function: Function\n\n\nclass ImageURL(BaseModel):\n    url: str\n\n\nclass MultimodalInputItem(BaseModel):\n    type: Literal[\"text\", \"image_url\"]\n    text: Optional[str] = None\n    image_url: Optional[ImageURL] = None\n\n\nclass ChatMessage(BaseModel):\n    role: Role\n    content: Optional[Union[str, List[MultimodalInputItem]]] = None\n    tool_calls: Optional[List[FunctionCall]] = None\n\n\nclass ChatCompletionMessage(BaseModel):\n    role: Optional[Role] = None\n    content: Optional[str] = None\n    tool_calls: Optional[List[FunctionCall]] = None\n\n\nclass ChatCompletionRequest(BaseModel):\n    model: str\n    messages: List[ChatMessage]\n    tools: Optional[List[FunctionAvailable]] = None\n    do_sample: Optional[bool] = None\n    temperature: Optional[float] = None\n    top_p: Optional[float] = None\n    n: int = 1\n    max_tokens: Optional[int] = None\n    stop: Optional[Union[str, List[str]]] = None\n    stream: bool = False\n\n\nclass ChatCompletionResponseChoice(BaseModel):\n    index: int\n    message: ChatCompletionMessage\n    finish_reason: Finish\n\n\nclass ChatCompletionStreamResponseChoice(BaseModel):\n    index: int\n    delta: ChatCompletionMessage\n    finish_reason: Optional[Finish] = None\n\n\nclass ChatCompletionResponseUsage(BaseModel):\n    prompt_tokens: int\n    completion_tokens: int\n    total_tokens: int\n\n\nclass ChatCompletionResponse(BaseModel):\n    id: str\n    object: Literal[\"chat.completion\"] = \"chat.completion\"\n    created: int = Field(default_factory=lambda: int(time.time()))\n    model: str\n    choices: List[ChatCompletionResponseChoice]\n    usage: ChatCompletionResponseUsage\n\n\nclass ChatCompletionStreamResponse(BaseModel):\n    id: str\n    object: Literal[\"chat.completion.chunk\"] = \"chat.completion.chunk\"\n    created: int = Field(default_factory=lambda: int(time.time()))\n    model: str\n    choices: List[ChatCompletionStreamResponseChoice]\n\n\nclass ScoreEvaluationRequest(BaseModel):\n    model: str\n    messages: List[str]\n    max_length: Optional[int] = None\n\n\nclass ScoreEvaluationResponse(BaseModel):\n    id: str\n    object: Literal[\"score.evaluation\"] = \"score.evaluation\"\n    model: str\n    scores: List[float]\n```"
        }
    ],
    "temperature": 0
}