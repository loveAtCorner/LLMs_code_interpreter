{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nimport os\nfrom copy import deepcopy\nfrom subprocess import Popen, TimeoutExpired\nfrom typing import TYPE_CHECKING, Any, Dict, Generator, Optional\n\nfrom transformers.trainer import TRAINING_ARGS_NAME\n\nfrom ..extras.constants import LLAMABOARD_CONFIG, PEFT_METHODS, TRAINING_STAGES\nfrom ..extras.misc import is_gpu_or_npu_available, torch_gc\nfrom ..extras.packages import is_gradio_available\nfrom .common import DEFAULT_CACHE_DIR, DEFAULT_CONFIG_DIR, QUANTIZATION_BITS, get_save_dir, load_config\nfrom .locales import ALERTS, LOCALES\nfrom .utils import abort_process, gen_cmd, get_eval_results, get_trainer_info, load_args, save_args, save_cmd\n\n\nif is_gradio_available():\n    import gradio as gr\n\n\nif TYPE_CHECKING:\n    from gradio.components import Component\n\n    from .manager import Manager\n\n\nclass Runner:\n    def __init__(self, manager: \"Manager\", demo_mode: bool = False) -> None:\n        self.manager = manager\n        self.demo_mode = demo_mode\n        \n        self.trainer: Optional[\"Popen\"] = None\n        self.do_train = True\n        self.running_data: Dict[\"Component\", Any] = None\n        \n        self.aborted = False\n        self.running = False\n\n    def set_abort(self) -> None:\n        self.aborted = True\n        if self.trainer is not None:\n            abort_process(self.trainer.pid)\n\n    def _initialize(self, data: Dict[\"Component\", Any], do_train: bool, from_preview: bool) -> str:\n        get = lambda elem_id: data[self.manager.get_elem_by_id(elem_id)]\n        lang, model_name, model_path = get(\"top.lang\"), get(\"top.model_name\"), get(\"top.model_path\")\n        dataset = get(\"train.dataset\") if do_train else get(\"eval.dataset\")\n\n        if self.running:\n            return ALERTS[\"err_conflict\"][lang]\n\n        if not model_name:\n            return ALERTS[\"err_no_model\"][lang]\n\n        if not model_path:\n            return ALERTS[\"err_no_path\"][lang]\n\n        if not dataset:\n            return ALERTS[\"err_no_dataset\"][lang]\n\n        if not from_preview and self.demo_mode:\n            return ALERTS[\"err_demo\"][lang]\n\n        if do_train:\n            if not get(\"train.output_dir\"):\n                return ALERTS[\"err_no_output_dir\"][lang]\n\n            stage = TRAINING_STAGES[get(\"train.training_stage\")]\n            if stage == \"ppo\" and not get(\"train.reward_model\"):\n                return ALERTS[\"err_no_reward_model\"][lang]\n        else:\n            if not get(\"eval.output_dir\"):\n                return ALERTS[\"err_no_output_dir\"][lang]\n\n        if not from_preview and not is_gpu_or_npu_available():\n            gr.Warning(ALERTS[\"warn_no_cuda\"][lang])\n\n        return \"\"\n\n    def _finalize(self, lang: str, finish_info: str) -> str:\n        finish_info = ALERTS[\"info_aborted\"][lang] if self.aborted else finish_info\n        self.trainer = None\n        self.aborted = False\n        self.running = False\n        self.running_data = None\n        torch_gc()\n        return finish_info\n\n    def _parse_train_args(self, data: Dict[\"Component\", Any]) -> Dict[str, Any]:\n        get = lambda elem_id: data[self.manager.get_elem_by_id(elem_id)]\n        model_name, finetuning_type = get(\"top.model_name\"), get(\"top.finetuning_type\")\n        user_config = load_config()\n\n        if get(\"top.quantization_bit\") in QUANTIZATION_BITS:\n            quantization_bit = int(get(\"top.quantization_bit\"))\n        else:\n            quantization_bit = None\n\n        args = dict(\n            stage=TRAINING_STAGES[get(\"train.training_stage\")],\n            do_train=True,\n            model_name_or_path=get(\"top.model_path\"),\n            cache_dir=user_config.get(\"cache_dir\", None),\n            preprocessing_num_workers=16,\n            finetuning_type=finetuning_type,\n            quantization_bit=quantization_bit,\n            quantization_method=get(\"top.quantization_method\"),\n            template=get(\"top.template\"),\n            rope_scaling=get(\"top.rope_scaling\") if get(\"top.rope_scaling\") in [\"linear\", \"dynamic\"] else None,\n            flash_attn=\"fa2\" if get(\"top.booster\") == \"flashattn2\" else \"auto\",\n            use_unsloth=(get(\"top.booster\") == \"unsloth\"),\n            visual_inputs=get(\"top.visual_inputs\"),\n            dataset_dir=get(\"train.dataset_dir\"),\n            dataset=\",\".join(get(\"train.dataset\")),\n            cutoff_len=get(\"train.cutoff_len\"),\n            learning_rate=float(get(\"train.learning_rate\")),\n            num_train_epochs=float(get(\"train.num_train_epochs\")),\n            max_samples=int(get(\"train.max_samples\")),\n            per_device_train_batch_size=get(\"train.batch_size\"),\n            gradient_accumulation_steps=get(\"train.gradient_accumulation_steps\"),\n            lr_scheduler_type=get(\"train.lr_scheduler_type\"),\n            max_grad_norm=float(get(\"train.max_grad_norm\")),\n            logging_steps=get(\"train.logging_steps\"),\n            save_steps=get(\"train.save_steps\"),\n            warmup_steps=get(\"train.warmup_steps\"),\n            neftune_noise_alpha=get(\"train.neftune_alpha\") or None,\n            optim=get(\"train.optim\"),\n            packing=get(\"train.packing\") or get(\"train.neat_packing\"),\n            neat_packing=get(\"train.neat_packing\"),\n            resize_vocab=get(\"train.resize_vocab\"),\n            use_llama_pro=get(\"train.use_llama_pro\"),\n            shift_attn=get(\"train.shift_attn\"),\n            report_to=\"all\" if get(\"train.report_to\") else \"none\",\n            use_galore=get(\"train.use_galore\"),\n            use_badam=get(\"train.use_badam\"),\n            output_dir=get_save_dir(model_name, finetuning_type, get(\"train.output_dir\")),\n            fp16=(get(\"train.compute_type\") == \"fp16\"),\n            bf16=(get(\"train.compute_type\") == \"bf16\"),\n            pure_bf16=(get(\"train.compute_type\") == \"pure_bf16\"),\n            plot_loss=True,\n            ddp_timeout=180000000,\n            include_num_input_tokens_seen=True,\n        )\n\n        \n        if get(\"top.checkpoint_path\"):\n            if finetuning_type in PEFT_METHODS:  \n                args[\"adapter_name_or_path\"] = \",\".join(\n                    [get_save_dir(model_name, finetuning_type, adapter) for adapter in get(\"top.checkpoint_path\")]\n                )\n            else:  \n                args[\"model_name_or_path\"] = get_save_dir(model_name, finetuning_type, get(\"top.checkpoint_path\"))\n\n        \n        if args[\"finetuning_type\"] == \"freeze\":\n            args[\"freeze_trainable_layers\"] = get(\"train.freeze_trainable_layers\")\n            args[\"freeze_trainable_modules\"] = get(\"train.freeze_trainable_modules\")\n            args[\"freeze_extra_modules\"] = get(\"train.freeze_extra_modules\") or None\n\n        \n        if args[\"finetuning_type\"] == \"lora\":\n            args[\"lora_rank\"] = get(\"train.lora_rank\")\n            args[\"lora_alpha\"] = get(\"train.lora_alpha\")\n            args[\"lora_dropout\"] = get(\"train.lora_dropout\")\n            args[\"loraplus_lr_ratio\"] = get(\"train.loraplus_lr_ratio\") or None\n            args[\"create_new_adapter\"] = get(\"train.create_new_adapter\")\n            args[\"use_rslora\"] = get(\"train.use_rslora\")\n            args[\"use_dora\"] = get(\"train.use_dora\")\n            args[\"pissa_init\"] = get(\"train.use_pissa\")\n            args[\"pissa_convert\"] = get(\"train.use_pissa\")\n            args[\"lora_target\"] = get(\"train.lora_target\") or \"all\"\n            args[\"additional_target\"] = get(\"train.additional_target\") or None\n\n            if args[\"use_llama_pro\"]:\n                args[\"freeze_trainable_layers\"] = get(\"train.freeze_trainable_layers\")\n\n        \n        if args[\"stage\"] == \"ppo\":\n            if finetuning_type in PEFT_METHODS:\n                args[\"reward_model\"] = \",\".join(\n                    [get_save_dir(model_name, finetuning_type, adapter) for adapter in get(\"train.reward_model\")]\n                )\n            else:\n                args[\"reward_model\"] = get_save_dir(model_name, finetuning_type, get(\"train.reward_model\"))\n\n            args[\"reward_model_type\"] = \"lora\" if finetuning_type == \"lora\" else \"full\"\n            args[\"ppo_score_norm\"] = get(\"train.ppo_score_norm\")\n            args[\"ppo_whiten_rewards\"] = get(\"train.ppo_whiten_rewards\")\n            args[\"top_k\"] = 0\n            args[\"top_p\"] = 0.9\n        elif args[\"stage\"] in [\"dpo\", \"kto\"]:\n            args[\"pref_beta\"] = get(\"train.pref_beta\")\n            args[\"pref_ftx\"] = get(\"train.pref_ftx\")\n            args[\"pref_loss\"] = get(\"train.pref_loss\")\n\n        \n        if args[\"use_galore\"]:\n            args[\"galore_rank\"] = get(\"train.galore_rank\")\n            args[\"galore_update_interval\"] = get(\"train.galore_update_interval\")\n            args[\"galore_scale\"] = get(\"train.galore_scale\")\n            args[\"galore_target\"] = get(\"train.galore_target\")\n\n        \n        if args[\"use_badam\"]:\n            args[\"badam_mode\"] = get(\"train.badam_mode\")\n            args[\"badam_switch_mode\"] = get(\"train.badam_switch_mode\")\n            args[\"badam_switch_interval\"] = get(\"train.badam_switch_interval\")\n            args[\"badam_update_ratio\"] = get(\"train.badam_update_ratio\")\n\n        \n        if get(\"train.val_size\") > 1e-6 and args[\"stage\"] != \"ppo\":\n            args[\"val_size\"] = get(\"train.val_size\")\n            args[\"eval_strategy\"] = \"steps\"\n            args[\"eval_steps\"] = args[\"save_steps\"]\n            args[\"per_device_eval_batch_size\"] = args[\"per_device_train_batch_size\"]\n\n        \n        if get(\"train.ds_stage\") != \"none\":\n            ds_stage = get(\"train.ds_stage\")\n            ds_offload = \"offload_\" if get(\"train.ds_offload\") else \"\"\n            args[\"deepspeed\"] = os.path.join(DEFAULT_CACHE_DIR, \"ds_z{}_{}config.json\".format(ds_stage, ds_offload))\n\n        return args\n\n    def _parse_eval_args(self, data: Dict[\"Component\", Any]) -> Dict[str, Any]:\n        get = lambda elem_id: data[self.manager.get_elem_by_id(elem_id)]\n        model_name, finetuning_type = get(\"top.model_name\"), get(\"top.finetuning_type\")\n        user_config = load_config()\n\n        if get(\"top.quantization_bit\") in QUANTIZATION_BITS:\n            quantization_bit = int(get(\"top.quantization_bit\"))\n        else:\n            quantization_bit = None\n\n        args = dict(\n            stage=\"sft\",\n            model_name_or_path=get(\"top.model_path\"),\n            cache_dir=user_config.get(\"cache_dir\", None),\n            preprocessing_num_workers=16,\n            finetuning_type=finetuning_type,\n            quantization_bit=quantization_bit,\n            quantization_method=get(\"top.quantization_method\"),\n            template=get(\"top.template\"),\n            rope_scaling=get(\"top.rope_scaling\") if get(\"top.rope_scaling\") in [\"linear\", \"dynamic\"] else None,\n            flash_attn=\"fa2\" if get(\"top.booster\") == \"flashattn2\" else \"auto\",\n            use_unsloth=(get(\"top.booster\") == \"unsloth\"),\n            visual_inputs=get(\"top.visual_inputs\"),\n            dataset_dir=get(\"eval.dataset_dir\"),\n            dataset=\",\".join(get(\"eval.dataset\")),\n            cutoff_len=get(\"eval.cutoff_len\"),\n            max_samples=int(get(\"eval.max_samples\")),\n            per_device_eval_batch_size=get(\"eval.batch_size\"),\n            predict_with_generate=True,\n            max_new_tokens=get(\"eval.max_new_tokens\"),\n            top_p=get(\"eval.top_p\"),\n            temperature=get(\"eval.temperature\"),\n            output_dir=get_save_dir(model_name, finetuning_type, get(\"eval.output_dir\")),\n        )\n\n        if get(\"eval.predict\"):\n            args[\"do_predict\"] = True\n        else:\n            args[\"do_eval\"] = True\n\n        if get(\"top.checkpoint_path\"):\n            if finetuning_type in PEFT_METHODS:  \n                args[\"adapter_name_or_path\"] = \",\".join(\n                    [get_save_dir(model_name, finetuning_type, adapter) for adapter in get(\"top.checkpoint_path\")]\n                )\n            else:  \n                args[\"model_name_or_path\"] = get_save_dir(model_name, finetuning_type, get(\"top.checkpoint_path\"))\n\n        return args\n\n    def _preview(self, data: Dict[\"Component\", Any], do_train: bool) -> Generator[Dict[\"Component\", str], None, None]:\n        output_box = self.manager.get_elem_by_id(\"{}.output_box\".format(\"train\" if do_train else \"eval\"))\n        error = self._initialize(data, do_train, from_preview=True)\n        if error:\n            gr.Warning(error)\n            yield {output_box: error}\n        else:\n            args = self._parse_train_args(data) if do_train else self._parse_eval_args(data)\n            yield {output_box: gen_cmd(args)}\n\n    def _launch(self, data: Dict[\"Component\", Any], do_train: bool) -> Generator[Dict[\"Component\", Any], None, None]:\n        output_box = self.manager.get_elem_by_id(\"{}.output_box\".format(\"train\" if do_train else \"eval\"))\n        error = self._initialize(data, do_train, from_preview=False)\n        if error:\n            gr.Warning(error)\n            yield {output_box: error}\n        else:\n            self.do_train, self.running_data = do_train, data\n            args = self._parse_train_args(data) if do_train else self._parse_eval_args(data)\n\n            os.makedirs(args[\"output_dir\"], exist_ok=True)\n            save_args(os.path.join(args[\"output_dir\"], LLAMABOARD_CONFIG), self._form_config_dict(data))\n\n            env = deepcopy(os.environ)\n            env[\"LLAMABOARD_ENABLED\"] = \"1\"\n            env[\"LLAMABOARD_WORKDIR\"] = args[\"output_dir\"]\n            if args.get(\"deepspeed\", None) is not None:\n                env[\"FORCE_TORCHRUN\"] = \"1\"\n\n            self.trainer = Popen(\"llamafactory-cli train {}\".format(save_cmd(args)), env=env, shell=True)\n            yield from self.monitor()\n\n    def _form_config_dict(self, data: Dict[\"Component\", Any]) -> Dict[str, Any]:\n        config_dict = {}\n        skip_ids = [\"top.lang\", \"top.model_path\", \"train.output_dir\", \"train.config_path\"]\n        for elem, value in data.items():\n            elem_id = self.manager.get_id_by_elem(elem)\n            if elem_id not in skip_ids:\n                config_dict[elem_id] = value\n\n        return config_dict\n\n    def preview_train(self, data):\n        yield from self._preview(data, do_train=True)\n\n    def preview_eval(self, data):\n        yield from self._preview(data, do_train=False)\n\n    def run_train(self, data):\n        yield from self._launch(data, do_train=True)\n\n    def run_eval(self, data):\n        yield from self._launch(data, do_train=False)\n\n    def monitor(self):\n        self.aborted = False\n        self.running = True\n\n        get = lambda elem_id: self.running_data[self.manager.get_elem_by_id(elem_id)]\n        lang, model_name, finetuning_type = get(\"top.lang\"), get(\"top.model_name\"), get(\"top.finetuning_type\")\n        output_dir = get(\"{}.output_dir\".format(\"train\" if self.do_train else \"eval\"))\n        output_path = get_save_dir(model_name, finetuning_type, output_dir)\n\n        output_box = self.manager.get_elem_by_id(\"{}.output_box\".format(\"train\" if self.do_train else \"eval\"))\n        progress_bar = self.manager.get_elem_by_id(\"{}.progress_bar\".format(\"train\" if self.do_train else \"eval\"))\n        loss_viewer = self.manager.get_elem_by_id(\"train.loss_viewer\") if self.do_train else None\n\n        while self.trainer is not None:\n            if self.aborted:\n                yield {\n                    output_box: ALERTS[\"info_aborting\"][lang],\n                    progress_bar: gr.Slider(visible=False),\n                }\n            else:\n                running_log, running_progress, running_loss = get_trainer_info(output_path, self.do_train)\n                return_dict = {\n                    output_box: running_log,\n                    progress_bar: running_progress,\n                }\n                if running_loss is not None:\n                    return_dict[loss_viewer] = running_loss\n\n                yield return_dict\n\n            try:\n                self.trainer.wait(2)\n                self.trainer = None\n            except TimeoutExpired:\n                continue\n\n        if self.do_train:\n            if os.path.exists(os.path.join(output_path, TRAINING_ARGS_NAME)):\n                finish_info = ALERTS[\"info_finished\"][lang]\n            else:\n                finish_info = ALERTS[\"err_failed\"][lang]\n        else:\n            if os.path.exists(os.path.join(output_path, \"all_results.json\")):\n                finish_info = get_eval_results(os.path.join(output_path, \"all_results.json\"))\n            else:\n                finish_info = ALERTS[\"err_failed\"][lang]\n\n        return_dict = {\n            output_box: self._finalize(lang, finish_info),\n            progress_bar: gr.Slider(visible=False),\n        }\n        yield return_dict\n\n    def save_args(self, data):\n        output_box = self.manager.get_elem_by_id(\"train.output_box\")\n        error = self._initialize(data, do_train=True, from_preview=True)\n        if error:\n            gr.Warning(error)\n            return {output_box: error}\n\n        lang = data[self.manager.get_elem_by_id(\"top.lang\")]\n        config_path = data[self.manager.get_elem_by_id(\"train.config_path\")]\n        os.makedirs(DEFAULT_CONFIG_DIR, exist_ok=True)\n        save_path = os.path.join(DEFAULT_CONFIG_DIR, config_path)\n\n        save_args(save_path, self._form_config_dict(data))\n        return {output_box: ALERTS[\"info_config_saved\"][lang] + save_path}\n\n    def load_args(self, lang: str, config_path: str):\n        output_box = self.manager.get_elem_by_id(\"train.output_box\")\n        config_dict = load_args(os.path.join(DEFAULT_CONFIG_DIR, config_path))\n        if config_dict is None:\n            gr.Warning(ALERTS[\"err_config_not_found\"][lang])\n            return {output_box: ALERTS[\"err_config_not_found\"][lang]}\n\n        output_dict: Dict[\"Component\", Any] = {output_box: ALERTS[\"info_config_loaded\"][lang]}\n        for elem_id, value in config_dict.items():\n            output_dict[self.manager.get_elem_by_id(elem_id)] = value\n\n        return output_dict\n\n    def check_output_dir(self, lang: str, model_name: str, finetuning_type: str, output_dir: str):\n        output_box = self.manager.get_elem_by_id(\"train.output_box\")\n        output_dict: Dict[\"Component\", Any] = {output_box: LOCALES[\"output_box\"][lang][\"value\"]}\n        if model_name and output_dir and os.path.isdir(get_save_dir(model_name, finetuning_type, output_dir)):\n            gr.Warning(ALERTS[\"warn_output_dir_exists\"][lang])\n            output_dict[output_box] = ALERTS[\"warn_output_dir_exists\"][lang]\n\n            output_dir = get_save_dir(model_name, finetuning_type, output_dir)\n            config_dict = load_args(os.path.join(output_dir, LLAMABOARD_CONFIG))  \n            for elem_id, value in config_dict.items():\n                output_dict[self.manager.get_elem_by_id(elem_id)] = value\n\n        return output_dict\n```"
        }
    ],
    "temperature": 0
}