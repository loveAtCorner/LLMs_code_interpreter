{
    "model": "qwen1.5-32b-chat-int4",
    "messages": [
        {
            "role": "system",
            "content": "你是python源码结构和逻辑的解析专家，非常擅长剖析核心代码的功能"
        },
        {
            "role": "user",
            "content": "请概括下面这个脚本的核心功能，然后该功能是否和大语言模型的指令精调任务有关```python\nfrom typing import TYPE_CHECKING, Dict\n\nfrom transformers.trainer_utils import SchedulerType\n\nfrom ...extras.constants import TRAINING_STAGES\nfrom ...extras.misc import get_device_count\nfrom ...extras.packages import is_gradio_available\nfrom ..common import DEFAULT_DATA_DIR, list_checkpoints, list_datasets\nfrom ..utils import change_stage, list_config_paths, list_output_dirs\nfrom .data import create_preview_box\n\n\nif is_gradio_available():\n    import gradio as gr\n\n\nif TYPE_CHECKING:\n    from gradio.components import Component\n\n    from ..engine import Engine\n\n\ndef create_train_tab(engine: \"Engine\") -> Dict[str, \"Component\"]:\n    input_elems = engine.manager.get_base_elems()\n    elem_dict = dict()\n\n    with gr.Row():\n        training_stage = gr.Dropdown(\n            choices=list(TRAINING_STAGES.keys()), value=list(TRAINING_STAGES.keys())[0], scale=1\n        )\n        dataset_dir = gr.Textbox(value=DEFAULT_DATA_DIR, scale=1)\n        dataset = gr.Dropdown(multiselect=True, allow_custom_value=True, scale=4)\n        preview_elems = create_preview_box(dataset_dir, dataset)\n\n    input_elems.update({training_stage, dataset_dir, dataset})\n    elem_dict.update(dict(training_stage=training_stage, dataset_dir=dataset_dir, dataset=dataset, **preview_elems))\n\n    with gr.Row():\n        learning_rate = gr.Textbox(value=\"5e-5\")\n        num_train_epochs = gr.Textbox(value=\"3.0\")\n        max_grad_norm = gr.Textbox(value=\"1.0\")\n        max_samples = gr.Textbox(value=\"100000\")\n        compute_type = gr.Dropdown(choices=[\"bf16\", \"fp16\", \"fp32\", \"pure_bf16\"], value=\"bf16\")\n\n    input_elems.update({learning_rate, num_train_epochs, max_grad_norm, max_samples, compute_type})\n    elem_dict.update(\n        dict(\n            learning_rate=learning_rate,\n            num_train_epochs=num_train_epochs,\n            max_grad_norm=max_grad_norm,\n            max_samples=max_samples,\n            compute_type=compute_type,\n        )\n    )\n\n    with gr.Row():\n        cutoff_len = gr.Slider(minimum=4, maximum=65536, value=1024, step=1)\n        batch_size = gr.Slider(minimum=1, maximum=1024, value=2, step=1)\n        gradient_accumulation_steps = gr.Slider(minimum=1, maximum=1024, value=8, step=1)\n        val_size = gr.Slider(minimum=0, maximum=1, value=0, step=0.001)\n        lr_scheduler_type = gr.Dropdown(choices=[scheduler.value for scheduler in SchedulerType], value=\"cosine\")\n\n    input_elems.update({cutoff_len, batch_size, gradient_accumulation_steps, val_size, lr_scheduler_type})\n    elem_dict.update(\n        dict(\n            cutoff_len=cutoff_len,\n            batch_size=batch_size,\n            gradient_accumulation_steps=gradient_accumulation_steps,\n            val_size=val_size,\n            lr_scheduler_type=lr_scheduler_type,\n        )\n    )\n\n    with gr.Accordion(open=False) as extra_tab:\n        with gr.Row():\n            logging_steps = gr.Slider(minimum=1, maximum=1000, value=5, step=5)\n            save_steps = gr.Slider(minimum=10, maximum=5000, value=100, step=10)\n            warmup_steps = gr.Slider(minimum=0, maximum=5000, value=0, step=1)\n            neftune_alpha = gr.Slider(minimum=0, maximum=10, value=0, step=0.1)\n            optim = gr.Textbox(value=\"adamw_torch\")\n\n        with gr.Row():\n            with gr.Column():\n                packing = gr.Checkbox()\n                neat_packing = gr.Checkbox()\n\n            with gr.Column():\n                resize_vocab = gr.Checkbox()\n                use_llama_pro = gr.Checkbox()\n\n            with gr.Column():\n                shift_attn = gr.Checkbox()\n                report_to = gr.Checkbox()\n\n    input_elems.update(\n        {\n            logging_steps,\n            save_steps,\n            warmup_steps,\n            neftune_alpha,\n            optim,\n            packing,\n            neat_packing,\n            resize_vocab,\n            use_llama_pro,\n            shift_attn,\n            report_to,\n        }\n    )\n    elem_dict.update(\n        dict(\n            extra_tab=extra_tab,\n            logging_steps=logging_steps,\n            save_steps=save_steps,\n            warmup_steps=warmup_steps,\n            neftune_alpha=neftune_alpha,\n            optim=optim,\n            packing=packing,\n            neat_packing=neat_packing,\n            resize_vocab=resize_vocab,\n            use_llama_pro=use_llama_pro,\n            shift_attn=shift_attn,\n            report_to=report_to,\n        )\n    )\n\n    with gr.Accordion(open=False) as freeze_tab:\n        with gr.Row():\n            freeze_trainable_layers = gr.Slider(minimum=-128, maximum=128, value=2, step=1)\n            freeze_trainable_modules = gr.Textbox(value=\"all\")\n            freeze_extra_modules = gr.Textbox()\n\n    input_elems.update({freeze_trainable_layers, freeze_trainable_modules, freeze_extra_modules})\n    elem_dict.update(\n        dict(\n            freeze_tab=freeze_tab,\n            freeze_trainable_layers=freeze_trainable_layers,\n            freeze_trainable_modules=freeze_trainable_modules,\n            freeze_extra_modules=freeze_extra_modules,\n        )\n    )\n\n    with gr.Accordion(open=False) as lora_tab:\n        with gr.Row():\n            lora_rank = gr.Slider(minimum=1, maximum=1024, value=8, step=1)\n            lora_alpha = gr.Slider(minimum=1, maximum=2048, value=16, step=1)\n            lora_dropout = gr.Slider(minimum=0, maximum=1, value=0, step=0.01)\n            loraplus_lr_ratio = gr.Slider(minimum=0, maximum=64, value=0, step=0.01)\n            create_new_adapter = gr.Checkbox()\n\n        with gr.Row():\n            use_rslora = gr.Checkbox()\n            use_dora = gr.Checkbox()\n            use_pissa = gr.Checkbox()\n            lora_target = gr.Textbox(scale=2)\n            additional_target = gr.Textbox(scale=2)\n\n    input_elems.update(\n        {\n            lora_rank,\n            lora_alpha,\n            lora_dropout,\n            loraplus_lr_ratio,\n            create_new_adapter,\n            use_rslora,\n            use_dora,\n            use_pissa,\n            lora_target,\n            additional_target,\n        }\n    )\n    elem_dict.update(\n        dict(\n            lora_tab=lora_tab,\n            lora_rank=lora_rank,\n            lora_alpha=lora_alpha,\n            lora_dropout=lora_dropout,\n            loraplus_lr_ratio=loraplus_lr_ratio,\n            create_new_adapter=create_new_adapter,\n            use_rslora=use_rslora,\n            use_dora=use_dora,\n            use_pissa=use_pissa,\n            lora_target=lora_target,\n            additional_target=additional_target,\n        )\n    )\n\n    with gr.Accordion(open=False) as rlhf_tab:\n        with gr.Row():\n            pref_beta = gr.Slider(minimum=0, maximum=1, value=0.1, step=0.01)\n            pref_ftx = gr.Slider(minimum=0, maximum=10, value=0, step=0.01)\n            pref_loss = gr.Dropdown(choices=[\"sigmoid\", \"hinge\", \"ipo\", \"kto_pair\", \"orpo\", \"simpo\"], value=\"sigmoid\")\n            reward_model = gr.Dropdown(multiselect=True, allow_custom_value=True)\n            with gr.Column():\n                ppo_score_norm = gr.Checkbox()\n                ppo_whiten_rewards = gr.Checkbox()\n\n    input_elems.update({pref_beta, pref_ftx, pref_loss, reward_model, ppo_score_norm, ppo_whiten_rewards})\n    elem_dict.update(\n        dict(\n            rlhf_tab=rlhf_tab,\n            pref_beta=pref_beta,\n            pref_ftx=pref_ftx,\n            pref_loss=pref_loss,\n            reward_model=reward_model,\n            ppo_score_norm=ppo_score_norm,\n            ppo_whiten_rewards=ppo_whiten_rewards,\n        )\n    )\n\n    with gr.Accordion(open=False) as galore_tab:\n        with gr.Row():\n            use_galore = gr.Checkbox()\n            galore_rank = gr.Slider(minimum=1, maximum=1024, value=16, step=1)\n            galore_update_interval = gr.Slider(minimum=1, maximum=1024, value=200, step=1)\n            galore_scale = gr.Slider(minimum=0, maximum=1, value=0.25, step=0.01)\n            galore_target = gr.Textbox(value=\"all\")\n\n    input_elems.update({use_galore, galore_rank, galore_update_interval, galore_scale, galore_target})\n    elem_dict.update(\n        dict(\n            galore_tab=galore_tab,\n            use_galore=use_galore,\n            galore_rank=galore_rank,\n            galore_update_interval=galore_update_interval,\n            galore_scale=galore_scale,\n            galore_target=galore_target,\n        )\n    )\n\n    with gr.Accordion(open=False) as badam_tab:\n        with gr.Row():\n            use_badam = gr.Checkbox()\n            badam_mode = gr.Dropdown(choices=[\"layer\", \"ratio\"], value=\"layer\")\n            badam_switch_mode = gr.Dropdown(choices=[\"ascending\", \"descending\", \"random\", \"fixed\"], value=\"ascending\")\n            badam_switch_interval = gr.Slider(minimum=1, maximum=1024, value=50, step=1)\n            badam_update_ratio = gr.Slider(minimum=0, maximum=1, value=0.05, step=0.01)\n\n    input_elems.update({use_badam, badam_mode, badam_switch_mode, badam_switch_interval, badam_update_ratio})\n    elem_dict.update(\n        dict(\n            badam_tab=badam_tab,\n            use_badam=use_badam,\n            badam_mode=badam_mode,\n            badam_switch_mode=badam_switch_mode,\n            badam_switch_interval=badam_switch_interval,\n            badam_update_ratio=badam_update_ratio,\n        )\n    )\n\n    with gr.Row():\n        cmd_preview_btn = gr.Button()\n        arg_save_btn = gr.Button()\n        arg_load_btn = gr.Button()\n        start_btn = gr.Button(variant=\"primary\")\n        stop_btn = gr.Button(variant=\"stop\")\n\n    with gr.Row():\n        with gr.Column(scale=3):\n            with gr.Row():\n                current_time = gr.Textbox(visible=False, interactive=False)\n                output_dir = gr.Dropdown(allow_custom_value=True)\n                config_path = gr.Dropdown(allow_custom_value=True)\n\n            with gr.Row():\n                device_count = gr.Textbox(value=str(get_device_count() or 1), interactive=False)\n                ds_stage = gr.Dropdown(choices=[\"none\", \"2\", \"3\"], value=\"none\")\n                ds_offload = gr.Checkbox()\n\n            with gr.Row():\n                resume_btn = gr.Checkbox(visible=False, interactive=False)\n                progress_bar = gr.Slider(visible=False, interactive=False)\n\n            with gr.Row():\n                output_box = gr.Markdown()\n\n        with gr.Column(scale=1):\n            loss_viewer = gr.Plot()\n\n    input_elems.update({output_dir, config_path, ds_stage, ds_offload})\n    elem_dict.update(\n        dict(\n            cmd_preview_btn=cmd_preview_btn,\n            arg_save_btn=arg_save_btn,\n            arg_load_btn=arg_load_btn,\n            start_btn=start_btn,\n            stop_btn=stop_btn,\n            current_time=current_time,\n            output_dir=output_dir,\n            config_path=config_path,\n            device_count=device_count,\n            ds_stage=ds_stage,\n            ds_offload=ds_offload,\n            resume_btn=resume_btn,\n            progress_bar=progress_bar,\n            output_box=output_box,\n            loss_viewer=loss_viewer,\n        )\n    )\n    output_elems = [output_box, progress_bar, loss_viewer]\n\n    cmd_preview_btn.click(engine.runner.preview_train, input_elems, output_elems, concurrency_limit=None)\n    start_btn.click(engine.runner.run_train, input_elems, output_elems)\n    stop_btn.click(engine.runner.set_abort)\n    resume_btn.change(engine.runner.monitor, outputs=output_elems, concurrency_limit=None)\n\n    lang = engine.manager.get_elem_by_id(\"top.lang\")\n    model_name: \"gr.Dropdown\" = engine.manager.get_elem_by_id(\"top.model_name\")\n    finetuning_type: \"gr.Dropdown\" = engine.manager.get_elem_by_id(\"top.finetuning_type\")\n\n    arg_save_btn.click(engine.runner.save_args, input_elems, output_elems, concurrency_limit=None)\n    arg_load_btn.click(\n        engine.runner.load_args, [lang, config_path], list(input_elems) + [output_box], concurrency_limit=None\n    )\n\n    dataset.focus(list_datasets, [dataset_dir, training_stage], [dataset], queue=False)\n    training_stage.change(change_stage, [training_stage], [dataset, packing], queue=False)\n    reward_model.focus(list_checkpoints, [model_name, finetuning_type], [reward_model], queue=False)\n    model_name.change(list_output_dirs, [model_name, finetuning_type, current_time], [output_dir], queue=False)\n    finetuning_type.change(list_output_dirs, [model_name, finetuning_type, current_time], [output_dir], queue=False)\n    output_dir.change(\n        list_output_dirs, [model_name, finetuning_type, current_time], [output_dir], concurrency_limit=None\n    )\n    output_dir.input(\n        engine.runner.check_output_dir,\n        [lang, model_name, finetuning_type, output_dir],\n        list(input_elems) + [output_box],\n        concurrency_limit=None,\n    )\n    config_path.change(list_config_paths, [current_time], [config_path], queue=False)\n\n    return elem_dict\n```"
        }
    ],
    "temperature": 0
}